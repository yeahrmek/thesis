\chapter{Introduction}
\label{chap:intro}


% Learning dependencies from data with neural networks has become ubiquituous.
% However, when it comes to problems without any structure in inputs (like in images or audio)
% other techniques can provide accurate results.
% Bayesian approaches are ones of the most appealing.
% First, they allow to avoid over-fitting by imposing
% prior distribution on the parameters of the model and then marginalizing them out
% which acts like a regularization.
% Second, bayesian models are probabilistic models,
% so the can provide uncertainty estimate of the predictions.



% This thesis focuses on building large-scale Gaussian Process models.
% Chapter~\ref{chap:gp_on_grids} describes efficient construction for the
% case of full factorial or incomplete factorial Design of Experiments.
% In Chapter~\ref{chap:unstructured_datasets} we develop general approach
% fo unstructured data sets based on random features.
% Chapter~\ref{chap:applications} is dedicated to applications of the proposed
% approaches on several problems, namely, density estimation, tensor completion
% and simultaneous localization and mapping.
% In this chapter we give necessary background on the kernel methods and Gaussian Processes.


Learning dependencies from data with neural networks has become ubiquitous.
However, when it comes to problems whose inputs lack structure (which is often the case for tabular data),
other techniques can provide accurate results.
Of these, Bayesian approaches are the most appealing.
First, they allow us to avoid over-fitting by imposing
prior distribution on the parameters of the model and then marginalizing them out;
this acts as a regularization.
Second, Bayesian models are probabilistic models,
so they can provide uncertainty estimate of the predictions.
Models based on the Gaussian process (GP) are few of the most popular bayesian tools,
especially for regression tasks, and are often applied to model physical characteristics,
time series forecasting, object tracking, and many others.

Technology and availability of computational resources allow the generation of
a lot of data for a given problem.
So, to succeed in solving the problem, the most crucial role is the
accurate analysis of the obtained data.
Generally, in data-driven approaches, the more data we have, the better model
we can construct.
The standard approach to build GP models heavily suffers from the computational
complexity that grows cubically with the data set's size.
Therefore, developing large-scale GP approaches is
an important research direction.

When we need to analyze some object of phenomenon, the data generation process is one of the
initial stages in the analysis.
A properly generated data set allows the capture of all the peculiarities of
the characteristics we are interested in.
In many engineering applications, the data is often generated on a grid.
This can be encouraged by an experimental setup.
For example, when designing some assembly part, an engineer can run a computer simulation
to measure its characteristics or can create the detail in full-scale
and conduct live experiments.
In the former case, there are some parameters that can be easily changed,
such as some external conditions, so it is natural to choose their values on a grid.
The parameters of the detail itself are much harder or expensive to change.
In this case, the data set has a particular structure.
Sometimes, there can be missing points in this structure due
to some simulation errors or the infeasibility of some set of parameters.
Nevertheless, possessing a structure in the data set, even with missing points,
can be utilized to build more efficient algorithms.
In many cases, however, the data set is unstructured.
To cover such cases, approximate models should be developed.

GP is a simple yet powerful model, which can be used
as a part of other complex systems, such as Bayesian optimization and
multi-fidelity modeling.
Developing accurate large-scale GP models allows us to
apply such models in other systems.
For example, GP models can be incorporated into deep neural networks,
density estimate pipeline, or simultaneous localization and mapping
problems in robotics.
Using GP models may not only result in better accuracy
but can also provide an analytical solution, regularize the final model, etc.

To sum up, the development of large-scale GP models for
structured and unstructured data sets is an actual research direction.
Providing examples on how to use different properties of such GP models
in different data-driven systems is essential and is of practical interest.

The topic of this thesis is large-scale Gaussian Process models
and its applications.
The subject of the research is
methods to build GP models in case of large structured and unstructured data sets
and the approaches to incorporate such models into different data-driven systems.
The main goal of this work is to develop computationally efficient
methods to fit large-scale GP models for structured and unstructured data sets
and to provide examples of building such models into different systems.
To achieve this goal, the following tasks should be considered:
\begin{enumerate}
    \item Development of the computationally efficient method for GP inference
    that takes into account the special structure of the data set.
    \item Development of the computationally efficient approximation for the GP inference
    in case of unstructured data sets.
    \item Implement the proposed approaches, demonstrate ways to build large-scale GP methods into different models.
\end{enumerate}

The scientific novelty of this work includes:
\begin{itemize}
    \item computationally efficient approach
    for exact GP inference in case of structured data sets with possible missing points.
    \item A new technique for approximation of the kernel function that enables
    computationally efficient GP inference.
    \item Theoretical analysis of the developed kernel function approximation.
    \item Development of several approaches based on the proposed methods, which achieves state-of-the-art performance in tensor completion problem, density estimate, and simultaneous localization and mapping.
    % We developed several approaches based on the proposed methods
    % and achieve state-of-the-art performance.
    % In particular, we designed algorithms for tensor completion,
    % probability density estimate and simultaneous localization and mapping.
\end{itemize}

The practical significance of the developed methods has beed demonstrated
on a set of real-world engineering problems.
The developed approaches for tensor completion problems,
probability density estimate, and simultaneous localization and mapping,
all based on the proposed methods, justifies the broad applicability of the obtained results.

The reliability of the presented results is supported
by double-blind reviews of the results at top international conferences,
through presentations and seminars at various academic venues, and by conducted numerical experiments.

The structure of the thesis is as follows:
the rest of this chapter introduces the GP models.
Chapter~\ref{chap:gp_on_grids} describes efficient construction for the
case of full factorial or incomplete factorial design of experiments (DoE).
In Chapter~\ref{chap:unstructured_datasets}, we develop a general approach
for unstructured data sets based on random features.
Chapter~\ref{chap:applications} is dedicated to applications of the proposed
approaches on several problems, namely, density estimation, tensor completion,
and simultaneous localization and mapping.
In this chapter, we give the necessary background on the kernel methods and GP.

